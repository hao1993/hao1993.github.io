---
layout:     post
title:      数据结构与算法
date:       2019-02-18
---

# 定义

从广义上讲，数据结构就是一组数据的存储结构。算法就是操作数据的一组方法。

从狭义上讲，是指某些著名的数据结构和算法，比如队列、栈、二分查找、动态规划 等。

数据结构是静态的，它只是组织数据的一种方式。如果不在它的基础上操作、构建算法，孤立存在的数据结构就是没用的。

20个最常用的最基础的数据结构与算法：

数据结构：**数组、链表、栈、队列、散列表、**二叉树、堆、**跳表**、图、Trie树

算法：**递归、排序、二分查找、**搜索、**哈希算法**、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法

# 时间复杂度、空间复杂度

时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。

空间复杂度的全称是渐进空间复杂度，表示算法的存储空间与数据规模之间的增长关系。

![ivatars](https://ws1.sinaimg.cn/large/006tKfTcly1g0azry5s8qj312g0ja46l.jpg)

最好情况时间复杂度、最坏情况时间复杂度、平均情况时间复杂度、均摊时间复杂度

均摊时间复杂度就是一种特殊的平均时间复杂度。

# 数据结构

## 数组

数组是一种线性表数据结构。它用一组**连续**的内存空间，来存储一组具有相同类型的数据。

从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。如果用a来表示数组的首地址，a[0]就是偏移为0的位置，也就是首地址，a[k]就表示偏移k个type_size的位置，所以计算a[k]的内存地址只需要用这个公式：

```c++
a[k]_address = base_address + k * type_size;
```

数组最大的特点是支持随机访问，但插入、删除操作也因此变得比较低效，平均情况时间复杂度为O(n)。

### 习题

- 求众数：[169](https://leetcode-cn.com/problems/majority-element/)  O(n方) 还差哈希解法

## 链表

链表不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用。

![ivatars](https://ws4.sinaimg.cn/large/006tKfTcly1g0cl8taelwj312i0nktg3.jpg)

时间复杂度：

![ivatars](https://ws4.sinaimg.cn/large/006tKfTcly1g0clb2xw4wj312o0f4aes.jpg)

单链表、双向链表、循环链表、双向循环链表

## 栈

栈结构：后进者先出，先进者后出

栈可以通过数组、链表来实现，入栈和出栈的时间复杂度都为O(1)。

内存中的堆栈和数据结构堆栈不是一个概念，可以说内存中的堆栈是真实存在的物理区，数据结构中的堆栈是抽象的数据存储结构。

内存空间在逻辑上分为三部分：代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区。

## 队列

队列：先进者先出

对于栈来说，我们只需要一个**栈顶指针**就可以了。但是队列需要两个指针：一个是head指针，指向队头；一个是tail指针，指向队尾。

使用阻塞队列，实现“生产者-消费者模型”。

线程安全的队列叫作并发队列。

### 应用

线程池没有空闲线程时，新的任务请求线程资源时，线程池该如何处理？各种处理策略又是如何实现的呢？

一般有两种处理策略。第一种是非阻塞的处理方式，直接拒绝任务请求；另一种是阻塞的处理方式，将请求排队，等到有空闲线程时，取出排队的请求继续处理。那如何存储排队的请求呢？

我们希望公平地处理每个排队的请求，先进者先服务，所以队列这种数据结构很适合来存储排队请求。队列有基于链表和基于数组这两种实现方式，这两种实现方式对于排队请求又有什么区别的？

基于链表的实现方式，可以实现一个支持无限排队的无界队列，但是可能会导致过多的请求排队等待，请求处理的响应时间过长。所以，针对响应时间比较敏感的系统，基于链表实现的无限排队的线程池是不合适的。

而基于数组实现的有界队列，队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。不过，设置一个合理的队列大小，也是非常有讲究的。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能。

除了前面讲到队列应用在线程池请求排队的场景之外，队列可以应用在任何有限资源池中，用于排队请求，比如数据库连接池等。**实际上，对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。**

## 跳表

链表加多级索引的结构，就是跳表。

- 它是一种个方面性能都比较优秀的动态数据结构，可以支持快速的插入、删除、查找操作，写起来也不复杂，甚至可以替代红黑树。

时间复杂度：

- 查询：O(logn) 这个查找的时间复杂度跟二分查找是一样的，换句话说，其实是基于单链表实现了二分查找。
- 插入：O(logn)
- 删除：O(logn)

空间复杂度：

- O(n)

作为一种动态数据结构，我们需要某种手段来维护索引与原始链表大小之间的平衡。也就是说，如果链表中节点多了，索引节点就相应地增加一些，避免复杂度退化，以及查找、插入、删除操作性能下降。

红黑树、AVL树这样的平衡二叉树，是通过左右旋的方式保持左右子树的大小平衡，而跳表是通过随机函数来维护前面提到的“平衡性”。

## 散列表

- 散列表也叫哈希表。
- 散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。

散列函数，顾名思义，它是一个函数。我们可以把它定义成**hash(key)**，其中key表示元素的键值，hash(key)的值表示经过散列函数计算得到的散列值。

业界著名的**MD5、SHA、CRC**等哈希算法，也无法完全避免散列冲突。而且，因为数组的存储空间有限，也会加大散列冲突的概率。

常用的散列冲突的解决方法：

- 开放寻址法

  核心思想是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。

  对于开放寻址冲突解决方法，除了**线性探测**方法之外，还有另外两种比较经典的探测方法，**二次探测**和**双重散列**。

- 链表法

  在散列表中，每个“桶”或者“槽”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。



散列表两个核心问题是**散列函数设计**和**散列冲突解决**。散列函数设计的好坏决定了散列冲突的概率，也就决定散列表的性能。

设计一个可以应对各种异常情况的工业级散列表，来避免在散列冲突的情况下，散列表性能的急剧下降，并且能抵抗散列碰撞攻击：

- 散列函数的设计不能太复杂
- 散列函数生成的值要尽可能随机并且均匀分布

```c++
hash("nice")
    = (("n" - "a") * 26*26*26 + ("i" - "a")*26*26 + ("c" - "a")*26+ ("e"-"a")) / 78978

```

针对散列表，当装载因子过大时，需要进行动态扩容，重新申请一个更大的散列表，将数据搬移到这个新散列表中。

如何选择冲突解决方法：

- 当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是Java中的ThreadLocalMap使用开放寻址法解决散列冲突的原因。
- 基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。

## 二叉树



# 算法

## 递归

学习数据结构和算法最难理解的知识点：一个是动态规划，另一个是递归。

递归是一种应用非常广泛的算法（或者编程技巧）。很多数据结构和算法的编码实现都要用到递归，比如DFS深度优先搜索、前中后序二叉树遍历等等。

递归需要满足的三个条件：

- 一个问题的解可以分解为几个字问题的解
- 这个问题与分解之后的字问题，除了数据规模不同，求解思路完全一样
- 存在递归终止条件

**写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。**

### 注意点

递归代码要警惕堆栈溢出；递归代码要警惕重复计算（可用散列表解决）

递归代码虽然简洁高效，但是，递归代码也有很多弊端。比如，堆栈溢出、重复计算、函数调用耗时多、空间复杂度高等，所以，在编写递归代码的时候，一定要控制好这些副作用。

编写递归代码的关键就是不要把自己绕进去，正确姿势是写出递推公式，找出终止条件，然后再翻译成递归代码。

### 调试方法：

1. 打印日志发现，递归值。
2. 结合条件断点进行调试。

## 排序

### 如何分析排序算法

1. 排序算法的执行效率

   - 最好情况、最坏情况、平均情况时间复杂度
   - 时间复杂度的系数、常数、低阶
   - 比较次数和交换（或移动）次数

2. 排序算法的内存消耗

   原地排序算法就是特指空间复杂度是O(1)的排序算法。

   冒泡、插入、选择都为原地排序算法。

3. 排序算法的稳定性

### 冒泡排序算法

1. 冒泡排序算法是原地排序算法
2. 是稳定的排序算法
3. 最好情况时间复杂度是O(n)，最坏情况时间复杂度是O(n方)，平均时间复杂度是O(n方)

### 插入排序

将数组中的数据分为两个区间，已排序区间和未排序区间。初始已排序区间只有一个元素，就是数组的第一个元素。插入算法的核心思想是取未排序区间中的元素，在已排序区间找到合适的插入位置将其插入，并保证已排序区间数据一直有序。重复这个过程，直到未排序区间中元素为空，算法结束。

1. 是原地排序算法
2. 是稳定的排序算法
3. 最好情况时间复杂度是O(n)，最坏情况时间复杂度是O(n方)，平均时间复杂度是O(n方)

### 选择排序

选择排序算法的实现思路有点类似插入排序，也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾。

1. 是原地排序算法

2. 是一种不稳定的排序算法

3. 最好情况时间复杂度、最坏情况时间复杂度、平均时间复杂度都是O(n方)


冒泡排序需要3个赋值操作，而插入排序只需要1个。随机生成10000个数组，每个数组中包含200个数据，冒泡需要700ms，插入排序需要100ms。

虽然冒泡排序和插入排序在时间复杂度上是一样的，都是O(n方)，但是如果我们希望把性能优化做到极致，那肯定首选插入排序。插入排序的算法思路也有很大的优化空间。例如：希尔排序。

### 归并排序&&快速排序

时间复杂度均为O(nlogn)

#### 归并排序

归并排序使用的是分治思想。分治，顾名思义，就是分而治之，将一个大问题分解成小问题。小的字问题解决了，大问题也就解决了。

分治是一个解决问题的处理思想，递归是一种编程技巧。

性能分析：

1. 是一个稳定的排序算法
2. 最好情况、最坏情况、平均情况，时间复杂度都是O(nlogn)
3. 空间复杂度是O(n)

#### 快速排序

快排的思想：如果要排序数组中下标从p到r之间的一组数据，我们选择p到r之间的任意一个数据作为pivot（分区点）。遍历p到r之间的数据，将小于pivot的放到左边，将大于pivot的放到右边，将pivot放到中间。

1. 是原地排序算法
2. 是不稳定排序算法
3. 在大部分情况下的时间复杂度都可以做到O(nlogn)，只有极端情况下，才会退化到O(n方)。有很多办法将这个概率降到很低。

### 桶排序&&计数排序&&基数排序

时间复杂度都为O(n)，因为这些排序算法的时间复杂度是线性的，所以我们把这类排序算法叫作**线性排序**。

之所以能做到线性的时间复杂度，主要原因是，这三个算法是非基于比较的排序算法，都不涉及元素之间的比较操作。

#### 桶排序

核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。

桶排序比较适合用在外部排序中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。

#### 计数排序

可以认为计数排序是桶排序的一种特殊情况。当要排序的n个数据，所处的范围并不大的时候，比如最大值是k，我们就可以把数据划分成k个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。

计数排序只能用在数据范围不大的场景中，如果数据范围k比要排序的数据n大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。

#### 基数排序

基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果a数据的高位比b数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到O(n)了。

## 哈希算法

将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法。

哈希算法的应用非常非常多，常见的七个：安全加密、唯一标识、数据校验、散列函数、负载均衡、数据分片、分布式存储。

### 安全加密

最常用于加密的哈希算法是MD5（MD5消息摘要算法）和SHA（安全散列算法）。其他加密算法，比如DES（数据加密标准）、AES（高级加密标准）。

对用于加密的哈希算法来说，有两点格外重要：

- 很难根据哈希值反向推导出原始数据
- 散列冲突的概率要很小

不管是什么哈希算法，我们只能尽量减少碰撞冲突的概率，理论上是没办法做到完全不冲突的。

这里就基于组合数学中一个非常基础的理论，鸽巢原理（也叫抽屉原理）。这个原理本身很简单，它是说，如果有10个鸽巢，有11只鸽子，那肯定有1个鸽巢中的鸽子数量多于1个，换句话说就是，肯定有2只鸽子在1个鸽巢内。

### 

