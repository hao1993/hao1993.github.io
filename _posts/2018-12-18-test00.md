---
layout:     post
title:      test01
date:       2018-12-18
---

# 第1章：温故而知新

## 1.1 从 Hello World 说起

```c
#include <stdio.h>

int main() 
{
    printf("Hello World\n");
    return 0;
}
```

- 程序为什么要被编译器编译了之后才可以运行？
- 编译器在把`C`语言程序转换成可以执行的机器码的过程中做了什么，怎么做的？
- 最后编译出来的可执行文件里面是什么？除了机器码还有什么？它们怎么存放的，怎么组织的？
- `#include <stdio.h>`是什么意思？把`stdio.h`包含进来意味着什么？`C`语言库又是什么？它怎么实现的？
- 不同的编译器`（Microsoft VC、GCC）`和不同的硬件平台`（x86、SPARC、MIPS、ARM）`，以及不同的操作系统`（Windows、Linux、UNIX、Solaris）`，最终编译出来的结果一样吗？为什么？
- `Hello World`程序是怎么运行起来的？操作系统是怎么装载它的？它从哪儿开始执行，到哪儿结束？`main`函数之前发生了什么？`main`函数结束之后又发生了什么？
- 如果没有操作系统，`Hello World`可以运行吗？如果要在一台没有操作系统的机器上运行`Hello World`需要什么？应该怎么实现？
- `printf`是怎么实现的？它为什么可以有不定数量的参数？为什么它能够在终端上输出字符串？
- `Hello World`程序在运行时，它在内存中是什么样子的？

## 1.2 万变不离其宗

- 对于系统程序开发者来说，计算机多如牛毛的硬件设备中，有三个部件最为关键，它们分别是中央处理器`CPU`、内存和`I/O`控制芯片，这三个部件几乎就是计算机的核心了；对于普通应用程序开发者来说，他们似乎除了要关心`CPU`以外，其他的硬件细节基本不用关心，对于一些高级平台的开发者来说（如`Java、.NET或脚本语言开发者`），连`CPU`都不需要关心，因为这些平台为它们提供了一个通用的抽象的计算机，他们只需要关心这个抽象的计算机就可以了。
- 随着`CPU`频率碰到了“天花板”，多核处理器越来越普及，对程序员开发程序的方式也将发生极大的变化。

## 1.3 站得高，望得远

- 计算机系统软件结构采用一种层的结构，有人说过一句名言：计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。
- 操作系统内核层对于硬件层来说是硬件接口的使用者，而硬件是接口的定义者，硬件的接口定义决定了操作系统内核，具体来讲就是驱动程序如何操作硬件，如何与硬件进行通信。这种接口往往被叫做`硬件规格`，硬件的生产厂商负责提供硬件规格，操作系统和驱动程序的开发者通过阅读硬件规格所规定的各种硬件编程接口标准来编写操作系统和驱动程序。

## 1.4 操作系统做什么

- 操作系统的一个功能是提供抽象的接口，另外一个主要功能是管理硬件资源。

### 1.4.1不要让`CPU`打盹

- **多任务系统**：操作系统接管了所有的硬件资源，并且本身运行在一个受硬件保护的级别。
- 所有的应用程序都以**进程**的方式运行在比操作系统权限更低的级别，每个进程都有自己独立的地址空间，使得进程之间的地址空间相互隔离。
- `CPU`由操作系统统一进行分配，每个进程根据进程优先级的高低都有机会得到`CPU`，但是，如果运行时间超出了一定的时间，操作系统会暂停该进程，将`CPU`资源分配给其他等待运行的进程。

- 这种`CPU`的分配方式即所谓的**抢占式**，操作系统可以强制剥夺`CPU`资源并且分配给它认为目前最需要的进程。
- 如果操作系统分配给每个进程的时间都很短，即`CPU`在多个进程间快速地切换，从而造成了很多进程都在同时运行的假象。目前几乎所有现代的操作系统都是采用这种方式，比如我们熟悉的`UNIX、Linux、Windows NT`，以及`Mac OS X`等流行的操作系统。

### 1.4.2 设备驱动

- 操作系统作为硬件层的上层，它是对硬件的管理和抽象。对于操作系统上面的运行库和应用程序来说，它们希望看到的是一个统一的硬件访问模式。作为应用程序的开发者，我们不希望在开发应用程序的时候直接读写硬件端口、处理硬件中断等这些繁琐的事情。
- 当成熟的操作系统出现以后，硬件逐渐被抽象成了一系列概念。

## 1.5 内存不够怎么办

- 地址空间不隔离，内存使用效率低，程序运行的地址不确定  解决这几个问题的思路就是使用我们前文提到过的法宝，增加中间层，即使用一种间接的地址访问方法。

### 1.5.1 关于隔离

- 用户程序在运行时不希望介入到这些复杂的存储器管理过程中，作为普通的程序，它需要的是一个简单的执行环境，有一个单一的地址空间、有自己的`CPU`，好像整个程序占有整个计算机而不用关心其他的程序（当然程序间通信的部分除外，因为这是程序主动要求跟其他程序通信和联系）。
- 虚拟地址空间是指虚拟的、人们想象出来的地址空间，其实它并不存在，每个进程都有自己独立的虚拟空间，而且每个进程只能访问自己的地址空间，这样就有效地做到了进程的隔离。

### 1.5.2 分段

- 分段的这种方法没有解决内存使用效率的问题。

- 事实上，更具程序的局部性原理，当一个程序在运行时，在某个时间段内，它只是频繁地用到了一小部分数据，也就是说，程序的很多数据其实在一个时间段内都是不会被用到的。人们很自然地想到了更小粒度的内存分割和映射的方法，是的程序的局部性原理得到充分的利用，大大提高了内存的使用率。这种方法就是**分页**。

### 1.5.3 分页

- 分页的基本方法是把地址空间人为地等分成固定大小的页，每一页的大小由硬件决定，或硬件支持多种大小的页，由操作系统选择决定页的大小。

- 虚拟存储的实现需要依靠硬件的支持，对于不同的`CPU`来说是不同的。但是几乎所有的硬件都采用一个叫`MMU`的部件来进行映射。
- 在页映射模式下，`CPU`发出的是`Virtual Address`，即我们的程序看到的是虚拟地址。经过`MMU`转换之后就变成了`Physical Address`。一般`MMU`都集成在`CPU`内部了，不会以独立的部件存在。

## 1.6众人拾柴火焰高

### 1.6.1 线程基础

- **线程**，有时被称为**轻量级进程**，是程序执行流的最小单元。一个标准的线程由线程**ID**、当前指令指针（**PC**）、寄存器集合和堆栈组成。通常意义上，一个进程由一个到多个线程组成，各个线程之间共享程序的内存空间（包括代码段、数据段、堆等）及一些进程级的资源（如打开文件和信号）。

- 大多数软件应用中，线程的数量都不止一个。多个线程可以互不干扰地并发执行，并共享进程的全局变量和堆的数据。
- 在单处理器对应多线程的情况下，并发是一种模拟出来的状态。操作系统会让这些多线程程序轮流执行，每次仅执行一小段时间（通常是几十到几百毫秒），这样每个线程就“看起来”在同时执行。这样的一个不断在处理器上切换不同的线程的行为称之为**线程调度**。
- 在线程调度中，线程通常拥有至少三种状态，分别是：
  1. 运行：此时线程正在执行。
  2. 就绪：此时线程可以立刻执行，但**CPU**已经被占用。
  3. 等待：此时线程正在等待某一事件（通常是I/O或同步）发生，无法执行。

- 在优先级调度的环境下，线程的优先级改变一般有三种方式。
  1. 用户指定优先级。
  2. 根据进入等待状态的频繁程度提升或降低优先级。
  3. 长时间得不到执行而被提升优先级。

### 1.6.2 线程安全

多线程程序处于一个多变的环境当中，可访问的全局变量和堆数据随时都可能被其他的线程改变。因此多线程程序在并发时数据的一致性变得非常重要。

- 自增（++）操作在多线程环境下会出现错误是因为这个操作被编译为汇编代码之后不止一条指令，因此在执行的时候可能执行了一半就被调度系统打断，去执行别的代码。我们把单指令的操作称为**原子的**，因为无论如何，单条指令的执行是不会被打断的。
- 为了避免多个线程同时读写同一个数据而产生不可预料的后果，我们要将各个线程对同一个数据的访问**同步**。所谓同步，即指一个线程访问数据未结束的时候，其他线程不得对同一个数据进行访问。如此，对数据的访问被原子化了。
- 同步的最常见方法是使用**锁**。

### 1.6.3 多线程内部情况

